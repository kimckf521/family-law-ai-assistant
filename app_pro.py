#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Australian Family Law AI Agent Pro - Bilingual with Claude API
æ¾³å¤§åˆ©äºšå®¶åº­æ³•AIä»£ç†ä¸“ä¸šç‰ˆ - åŒè¯­ç‰ˆå¸¦Claude API
"""

import streamlit as st
import json
import re
import os
from datetime import datetime
from typing import List, Dict, Optional
import anthropic

# Language configurations
LANGUAGES = {
    'en': {
        'page_title': 'Family Law AI Assistant Pro',
        'title': 'âš–ï¸ Australian Family Law AI Assistant Pro',
        'subtitle': 'AI-powered legal assistant with intelligent answers',
        'search_placeholder': 'Ask your question about family law...',
        'search_button': 'ğŸ¤– Ask AI',
        'loading': 'ğŸ”„ Loading AI agent...',
        'thinking': 'ğŸ¤” AI is thinking...',
        'searching': 'ğŸ” Searching knowledge base...',
        'results_title': 'Relevant Content',
        'ai_answer_title': 'ğŸ’¡ AI Answer',
        'no_api_key': 'âš ï¸ No API key configured. Using search-only mode.',
        'about': 'About',
        'about_text': '''
**Pro Version Features:**
- ğŸ¤– AI-powered intelligent answers
- ğŸ” Advanced semantic search
- ğŸ“„ Automatic citations with page numbers
- ğŸ’¬ Natural language understanding

**Powered by:**
- Claude Sonnet 4 AI
- 666-page Family Law knowledge base
- 1,042 searchable content chunks

**Note:** This is the Pro version with AI capabilities. Requires Anthropic API key.
        ''',
        'search_mode': 'Search Only Mode',
        'ai_mode': 'AI Mode',
        'toggle_mode': 'Mode',
        'page_label': 'Page',
        'category_label': 'Category',
        'clear_chat': 'Clear Chat',
        'search_history': 'Chat History',
        'footer': 'Pro version with AI | Built with â¤ï¸ for the legal community'
    },
    'zh': {
        'page_title': 'å®¶åº­æ³•AIåŠ©æ‰‹ä¸“ä¸šç‰ˆ',
        'title': 'âš–ï¸ æ¾³å¤§åˆ©äºšå®¶åº­æ³•AIåŠ©æ‰‹ä¸“ä¸šç‰ˆ',
        'subtitle': 'AIé©±åŠ¨çš„æ³•å¾‹åŠ©æ‰‹ï¼Œæä¾›æ™ºèƒ½å›ç­”',
        'search_placeholder': 'è¯¢é—®æ‚¨çš„å®¶åº­æ³•é—®é¢˜...',
        'search_button': 'ğŸ¤– è¯¢é—®AI',
        'loading': 'ğŸ”„ æ­£åœ¨åŠ è½½AIä»£ç†...',
        'thinking': 'ğŸ¤” AIæ­£åœ¨æ€è€ƒ...',
        'searching': 'ğŸ” æœç´¢çŸ¥è¯†åº“ä¸­...',
        'results_title': 'ç›¸å…³å†…å®¹',
        'ai_answer_title': 'ğŸ’¡ AIå›ç­”',
        'no_api_key': 'âš ï¸ æœªé…ç½®APIå¯†é’¥ã€‚ä½¿ç”¨çº¯æœç´¢æ¨¡å¼ã€‚',
        'about': 'å…³äº',
        'about_text': '''
**ä¸“ä¸šç‰ˆåŠŸèƒ½ï¼š**
- ğŸ¤– AIé©±åŠ¨çš„æ™ºèƒ½å›ç­”
- ğŸ” é«˜çº§è¯­ä¹‰æœç´¢
- ğŸ“„ è‡ªåŠ¨å¼•ç”¨é¡µç 
- ğŸ’¬ è‡ªç„¶è¯­è¨€ç†è§£

**æŠ€æœ¯æ”¯æŒï¼š**
- Claude Sonnet 4 AI
- 666é¡µå®¶åº­æ³•çŸ¥è¯†åº“
- 1,042ä¸ªå¯æœç´¢å†…å®¹å—

**æ³¨æ„ï¼š** è¿™æ˜¯å¸¦AIåŠŸèƒ½çš„ä¸“ä¸šç‰ˆã€‚éœ€è¦Anthropic APIå¯†é’¥ã€‚
        ''',
        'search_mode': 'çº¯æœç´¢æ¨¡å¼',
        'ai_mode': 'AIæ¨¡å¼',
        'toggle_mode': 'æ¨¡å¼',
        'page_label': 'é¡µç ',
        'category_label': 'ç±»åˆ«',
        'clear_chat': 'æ¸…ç©ºå¯¹è¯',
        'search_history': 'å¯¹è¯å†å²',
        'footer': 'AIä¸“ä¸šç‰ˆ | ä¸ºæ³•å¾‹ç¤¾åŒºç”¨â¤ï¸æ„å»º'
    }
}

# Page configuration
st.set_page_config(
    page_title="Family Law AI Pro | å®¶åº­æ³•AIä¸“ä¸šç‰ˆ",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main {padding: 0rem 1rem;}
    .chat-message {
        padding: 1.5rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
    }
    .user-message {
        background-color: #e3f2fd;
        border-left: 5px solid #2196F3;
    }
    .ai-message {
        background-color: #e8f5e9;
        border-left: 5px solid #4CAF50;
    }
    .search-result {
        background-color: #f5f5f5;
        border-left: 5px solid #9E9E9E;
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 0.5rem;
    }
    .page-ref {
        background-color: #1976D2;
        color: white;
        padding: 2px 8px;
        border-radius: 4px;
        font-size: 0.85em;
        font-weight: bold;
        margin: 0 4px;
    }
</style>
""", unsafe_allow_html=True)


class FamilyLawAIAgent:
    """Family Law AI Agent Pro | å®¶åº­æ³•AIä»£ç†ä¸“ä¸šç‰ˆ"""
    
    def __init__(self, chunks_path: str, api_key: Optional[str] = None):
        self.chunks = self._load_chunks(chunks_path)
        self.claude_client = None
        if api_key:
            try:
                self.claude_client = anthropic.Anthropic(api_key=api_key)
            except Exception as e:
                st.error(f"Failed to initialize Claude API: {str(e)}")
    
    @st.cache_data
    def _load_chunks(_self, path: str):
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data['chunks']
    
    def search(self, query: str, n_results: int = 5) -> List[Dict]:
        """Search relevant content | æœç´¢ç›¸å…³å†…å®¹"""
        query_lower = query.lower()
        query_terms = set(re.findall(r'\b\w+\b', query_lower))
        
        scored_chunks = []
        for chunk in self.chunks:
            text_lower = chunk['text'].lower()
            score = 0
            
            # Exact phrase match
            if query_lower in text_lower:
                score += 10
            
            # Term matching
            text_terms = set(re.findall(r'\b\w+\b', text_lower))
            matching_terms = query_terms & text_terms
            score += len(matching_terms) * 2
            
            # Boost by term frequency
            for term in matching_terms:
                score += text_lower.count(term)
            
            if score > 0:
                scored_chunks.append({
                    'chunk': chunk,
                    'score': score
                })
        
        scored_chunks.sort(key=lambda x: x['score'], reverse=True)
        return scored_chunks[:n_results]
    
    def generate_ai_answer(self, query: str, context_chunks: List[Dict], language: str = 'en') -> str:
        """Generate AI answer | ç”ŸæˆAIå›ç­”"""
        if not self.claude_client:
            return None
        
        context_text = "\n\n".join([
            f"[Page {chunk['chunk']['page']}] {chunk['chunk']['text']}"
            for chunk in context_chunks[:5]
        ])
        
        if language == 'zh':
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ¾³å¤§åˆ©äºšå®¶åº­æ³•ä¸“å®¶åŠ©æ‰‹ã€‚åŸºäºæä¾›çš„æ³•å¾‹æ–‡æœ¬ï¼Œç”¨ä¸­æ–‡å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

è¦æ±‚ï¼š
1. åªä½¿ç”¨æä¾›çš„æ–‡æœ¬å†…å®¹å›ç­”
2. æ˜ç¡®å¼•ç”¨é¡µç ï¼ˆå¦‚"æ ¹æ®ç¬¬123é¡µ..."ï¼‰
3. å¦‚æœæ–‡æœ¬ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯šå®åœ°è¯´æ˜
4. ä½¿ç”¨æ¸…æ™°ã€ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€
5. æä¾›å…·ä½“ã€å®ç”¨çš„ä¿¡æ¯
6. æé†’è¿™æ˜¯æ³•å¾‹ä¿¡æ¯ï¼Œä¸æ˜¯æ³•å¾‹å»ºè®®"""

            user_prompt = f"""åŸºäºä»¥ä¸‹æ³•å¾‹æ–‡æœ¬å›ç­”é—®é¢˜ã€‚

æ³•å¾‹æ–‡æœ¬ï¼š
{context_text}

ç”¨æˆ·é—®é¢˜ï¼š{query}

è¯·ç”¨ä¸­æ–‡æä¾›æ¸…æ™°ã€ä¸“ä¸šçš„å›ç­”ï¼Œå¹¶å¼•ç”¨ç›¸å…³é¡µç ã€‚"""
        else:
            system_prompt = """You are an Australian Family Law expert assistant. Answer questions based on the provided legal text.

Requirements:
1. Only use the provided text content
2. Clearly cite page numbers (e.g., "According to page 123...")
3. If information is not in the text, honestly state this
4. Use clear, professional but accessible language
5. Provide specific, practical information
6. Remind that this is legal information, not legal advice"""

            user_prompt = f"""Answer the question based on the following legal text.

Legal Text:
{context_text}

Question: {query}

Provide a clear, professional answer with page citations."""
        
        try:
            response = self.claude_client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=1000,
                system=system_prompt,
                messages=[{
                    "role": "user",
                    "content": user_prompt
                }]
            )
            return response.content[0].text
        except Exception as e:
            return f"Error generating AI response: {str(e)}"


def detect_language(text: str) -> str:
    """Detect if text contains Chinese | æ£€æµ‹æ˜¯å¦åŒ…å«ä¸­æ–‡"""
    chinese_chars = re.findall(r'[\u4e00-\u9fff]', text)
    return 'zh' if len(chinese_chars) > len(text) * 0.3 else 'en'


def init_session_state():
    """Initialize session state | åˆå§‹åŒ–çŠ¶æ€"""
    if 'language' not in st.session_state:
        st.session_state.language = 'en'
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    if 'agent' not in st.session_state:
        api_key = os.environ.get('ANTHROPIC_API_KEY')
        with st.spinner(LANGUAGES[st.session_state.language]['loading']):
            # Use relative path for Streamlit Cloud
            current_dir = os.path.dirname(os.path.abspath(__file__))
            chunks_path = os.path.join(current_dir, 'family_law_chunks.json')
            st.session_state.agent = FamilyLawAIAgent(chunks_path, api_key=api_key)
    if 'use_ai' not in st.session_state:
        st.session_state.use_ai = st.session_state.agent.claude_client is not None


def main():
    init_session_state()
    
    lang_data = LANGUAGES[st.session_state.language]
    
    # Sidebar
    with st.sidebar:
        # Language switcher
        st.markdown("### ğŸŒ Language | è¯­è¨€")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ‡¬ğŸ‡§ English", use_container_width=True,
                        type="primary" if st.session_state.language == 'en' else "secondary"):
                st.session_state.language = 'en'
                st.rerun()
        with col2:
            if st.button("ğŸ‡¨ğŸ‡³ ä¸­æ–‡", use_container_width=True,
                        type="primary" if st.session_state.language == 'zh' else "secondary"):
                st.session_state.language = 'zh'
                st.rerun()
        
        st.markdown("---")
        
        # Mode toggle
        if st.session_state.agent.claude_client:
            st.markdown(f"### {lang_data['toggle_mode']}")
            use_ai = st.toggle(
                lang_data['ai_mode'] if st.session_state.use_ai else lang_data['search_mode'],
                value=st.session_state.use_ai,
                key="ai_toggle"
            )
            st.session_state.use_ai = use_ai
        else:
            st.warning(lang_data['no_api_key'])
        
        st.markdown("---")
        
        # About
        with st.expander(lang_data['about'], expanded=False):
            st.markdown(lang_data['about_text'])
        
        # Chat controls
        if st.session_state.messages:
            st.markdown("---")
            if st.button(lang_data['clear_chat'], use_container_width=True):
                st.session_state.messages = []
                st.rerun()
    
    # Main content
    st.title(lang_data['title'])
    st.markdown(f"*{lang_data['subtitle']}*")
    st.markdown("---")
    
    # Chat interface
    for message in st.session_state.messages:
        if message["role"] == "user":
            st.markdown(f'<div class="chat-message user-message">ğŸ‘¤ {message["content"]}</div>',
                       unsafe_allow_html=True)
        elif message["role"] == "assistant":
            st.markdown(f'<div class="chat-message ai-message">ğŸ¤– {message["content"]}</div>',
                       unsafe_allow_html=True)
        elif message["role"] == "search":
            st.markdown(f'<div class="chat-message search-result">ğŸ” {message["content"]}</div>',
                       unsafe_allow_html=True)
    
    # Input
    col1, col2 = st.columns([5, 1])
    with col1:
        query = st.text_input(
            "query_input",
            placeholder=lang_data['search_placeholder'],
            label_visibility="collapsed",
            key="user_query"
        )
    with col2:
        search_button = st.button(lang_data['search_button'], use_container_width=True, type="primary")
    
    # Process query
    if search_button and query:
        # Auto-detect language
        detected_lang = detect_language(query)
        if detected_lang != st.session_state.language:
            st.session_state.language = detected_lang
            lang_data = LANGUAGES[detected_lang]
        
        # Add user message
        st.session_state.messages.append({
            "role": "user",
            "content": query
        })
        
        # Search
        with st.spinner(lang_data['searching']):
            results = st.session_state.agent.search(query, n_results=5)
        
        # Display search results
        if results:
            search_summary = f"{lang_data['results_title']}:\n"
            for idx, result in enumerate(results[:3]):
                chunk = result['chunk']
                page = chunk.get('page', 'N/A')
                text_preview = chunk['text'][:150] + "..."
                search_summary += f"\nğŸ“„ {lang_data['page_label']} {page}: {text_preview}"
            
            st.session_state.messages.append({
                "role": "search",
                "content": search_summary
            })
        
        # Generate AI answer if enabled
        if st.session_state.use_ai and results:
            with st.spinner(lang_data['thinking']):
                ai_answer = st.session_state.agent.generate_ai_answer(
                    query, results, st.session_state.language
                )
                if ai_answer:
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": ai_answer
                    })
        
        st.rerun()
    
    # Footer
    st.markdown("---")
    st.markdown(f"<div style='text-align: center; color: #666;'>{lang_data['footer']}</div>",
               unsafe_allow_html=True)


if __name__ == "__main__":
    main()
